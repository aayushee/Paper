The following issues encountered during algorithm design and empirical verification are worth discussion:
%\begin{itemize}
(1)  A linear combination of parameters was used in our experiments for calculation of Document Index and Influential Person Index. Furthermore, they are weighted equally in experiments performed with our data. The heuristics can be re-weighted according to user requirements. 
%\item
(2) The parameters for calculation of DI and IPI can also be learned by performing regression analysis using a manually developed sample of influential people and obtaining the complete list of ranked influential people based on the learned parameters.
%\item
(3) The Normalized Document Length (NDL) defined for calculation of DI is normalized using the maximum length of any document in the dataset. However, there might exist other ways of normalization of Document Length like using total number of tokens in a person's document list or total number of tokens in the complete dataset which can be tuned based on the requirements of the application.
%\item
(4) Lists of influential people contain several false positives. This is due to noise in the OCR data -- several location and organization names have been recognized as person entities even after performing spelling correction resulting in false detection during PNER for some influential entities like ``van cortlandt", ``ann arbor" ,  and ``sandy hook". We recognize that there there is no gold standard data to measure the accuracy in our case therefore, we rely on the NER software's accuracy for recognizing person names.
 %There is also the problem of resolution of person name disambiguation in cases where persons like ``mrs martins" , ``mrs oakes", etc. have been recognized as influential.  
%\item 
(5) We have used the topic with highest probability for topic detection in the People Gazetteer. However, there could be other topics of interest. The algorithm can be modified to assign top N (N can be chosen depending on the topic distribution probabilities in the corpus) topics to a document by updating NSIM as follows: 
 $NSIM=  \frac{\sum_{i=1}^{N}\text{SIM}_i} { N\times n}$
Here, $N$=set of topics assigned to a document during topic detection,  $t_i$ =frequency of $i^{th}$ topic in all documents in a person's list and $n$= total number of documents in a person's list.
%\item
(6) The choice of parameters for topic detection also affects the detection of influential people which is evident from the fact that we get different ranking of influential people for the two different LDA topic model settings used. 





\noindent \textbf {An alternative approach to detection of influential people: }
A heuristics based approach for finding influential people has been discussed in the previous section. It can be easily seen that the gazetteer comprises of a list of person names and a \emph{bag} of articles for each person from which his/her influence score can be learnt. This motivates discussion of whether an alternative approach involving multiple instance clustering (such as the \textbf{BA}g Level \textbf{M}ulti-\textbf{I}nstance \textbf{C}lustering (BAMIC \cite{zhang2009multi}) can be used for the problem. The procedure works as follows: 
 Cluster person entities into \emph{influential} or \emph{non-influential} categories by considering each person entity as having a bag of news articles in which their names occur.
 %It considers clustering objects that consist of sets of instances for clustering rather than single instance clustering. 
 %Instances of the same object are represented by a bag and the k-medoids algorithm is used to cluster those bags. 
 %The k-medoids algorithm is adapted to use average Hausdorff distance to measure similarity between instances. It averages the distance between each instance in one bag and its nearest instance in the other bag and partitions dataset into k disjoint groups each containing a set of bags. 
 %BAMIC is applied to MUSK 1 and MUSK 2 datasets available publically\footnote{https://archive.ics.uci.edu/ml/datasets.html} which consist of 92 bags with 476 instances and 102 bags with 6598 instances, respectively and is used to test whether molecules are qualified to be used in a drug or not.
 %This approach can be used to detect influential people as follows:  
The parameters used for calculating DI in the previous section i.e. NDL,NTF and NSIM can be used as features associated with each article instance in the bag. The group of \emph{influential} people identified can then be ranked using an appropriate ranking score.
%Such a method can avoid choice of parameter weights, biasing of results with respect to any specific parameter and decide which article plays a role in determining whether a person is influential or not. 
The open source version of the BAMIC algorithm was used to compare results with the heuristic based approach proposed in this paper. However, the clustering algorithm does not scale very well. Our dataset consisted of roughly 40000 person named entities -- it was estimated that it would take around 200 days to get the clusters of influential and non-influential people.  Hence these results of comparison are not presented. 
%Since BAMIC has been used for smaller datasets in earlier studies, we believe if the BAMIC algorithm can be scaled for larger datasets, it can be applied to our scenario easily.
%\end{itemize}